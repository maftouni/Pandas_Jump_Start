{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## In Jupyter, one can easily document and report what they have done and many use it to present their results. \n\n#### Some useful Jupyter **shortcuts** are: \n##### $\\;\\;\\;\\;\\;\\;$- Ctrl + Enter (run current cell) \n##### $\\;\\;\\;\\;\\;\\;$- Alt+Enter (run the current and make a new cell) \n##### $\\;\\;\\;\\;\\;\\;$- Shift + Enter (run and move to the next cell) \n\n#### When in the **command mode**: \n##### $\\;\\;\\;\\;\\;\\;$- **Use h to pull up the list of all the shortcuts.** Some of the useful ones are:\n##### $\\;\\;\\;\\;\\;\\;$- m (turn the cell into a markdown cell),1 (turn the text into a large header), y (turn it to code cell), k and j are to move up and down, a and b to insert cell above and below \n\n#### In the **code cells**: \n##### $\\;\\;\\;\\;\\;\\;$- Tab (for code completion)\n##### $\\;\\;\\;\\;\\;\\;$- Shift + Tab (for pulling up the help documentation)\n##### $\\;\\;\\;\\;\\;\\;$- Ctrl + ]    (indent) ","metadata":{}},{"cell_type":"markdown","source":"## The notebook is as follows:\n#### $\\;\\;\\;\\;\\;\\;$- Reading Data into DataFrames\n#### $\\;\\;\\;\\;\\;\\;$- Inserting, Dropping, and Renaming rows and columns\n#### $\\;\\;\\;\\;\\;\\;$- Data Cleaning (Handling missing values, and converting data formats)\n#### $\\;\\;\\;\\;\\;\\;$- Exploratory Data Analysis \n#### $\\;\\;\\;\\;\\;\\;$- Data Visualization\n#### $\\;\\;\\;\\;\\;\\;$- Hypothesis formulation/Conclusion","metadata":{}},{"cell_type":"code","source":"#Library\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport datetime\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\npy.init_notebook_mode(connected = True)\nimport plotly.express as px","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Introduction to DataFrames  \n### Let's create an empty dataframe first!","metadata":{}},{"cell_type":"code","source":"col = ['Name','Age']\ndf = pd.DataFrame(columns = col)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There are multiple ways to create a DataFrames:","metadata":{}},{"cell_type":"code","source":"# using list of lists\ndata = [['John', 29], ['Hannah', 35], ['Juli', 26]]\ndf = pd.DataFrame(data, columns = ['Name', 'Age'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using dictionaries\nData = {'Name':['John','Hannah','Juli'],'Age':[29,35,26]}\ndf = pd.DataFrame(Data)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### But, the most common case is to read the data from an Excel or CSV file into the dataframe using **pd.read_csv()**:","metadata":{}},{"cell_type":"markdown","source":"# Example dataset: Melbourne House Prices\n### Analysing housing data in Melbourne\n![](https://cdn.britannica.com/64/190464-050-B74E1FD9/view-central-business-district-Melbourne-train-station.jpg)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('melb_data.csv')\nprint('Dataset has ',df.shape[0],' records and ',df.shape[1], ' columns' )\nprint(' ')\ndf.head() # head shows the first 5 rows by default","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Renaming a column","metadata":{}},{"cell_type":"code","source":"print('Before Rename: ',df.columns)\ndf = df.rename(columns = {'SellerG':'Real_Estate_Agent'})\n# Column names in the dataset\nprint('After Rename: ',df.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inserting a new column","metadata":{}},{"cell_type":"code","source":"# new column\ndf['test'] = 'test column'\ndf.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping a column","metadata":{}},{"cell_type":"code","source":"df.drop('test' , axis = 1,inplace = True) # you can set df equal to this statement here to overwrite or use inplace = True\ndf.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inserting a new row","metadata":{}},{"cell_type":"code","source":"new_row = {'Suburb': 'Abbotsford', 'Address': '26 Bloomburg St', 'Rooms': 4, 'Type': 'h', 'Price': 1033030.0, 'Method': 'S', 'Real_Estate_Agent': 'Biggin', 'Date': '4/02/2016', 'Distance': 2.5, 'Postcode': 3067.0, 'Bedroom2': 2.0, 'Bathroom': 1.0, 'Car': 0.0, 'Landsize': 156.0, 'BuildingArea': 79.0, 'YearBuilt': 1900.0, 'CouncilArea': 'Yarra', 'Lattitude': -37.8079, 'Longtitude': 144.9934, 'Regionname': 'Northern Metropolitan', 'Propertycount': 4019.0}\nprint(len(df))\ndf = df.append(new_row , ignore_index = True)  # ignore_index should be set to True to append a dict to the dataframe\nprint(len(df))\ndf.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping a row","metadata":{}},{"cell_type":"code","source":"df.drop(len(df)-1,inplace = True)\ndf.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DataFrame Summary","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Descriptive statistics of the DataFrame","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"memory_usage0 = df['Type'].memory_usage()  #select a column with square brackets [ ]\nmemory_usage1 = df.Type.memory_usage() #select a column with .col_name\nprint('Initial memory usage: ',memory_usage1,memory_usage0)\ndf.Type.unique() #Unique values in the column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If the number of distinct categories are very few compared to the number of rows, we can save a substantial amount of memory by using category data type\n\ndf['Type'] = df['Type'].astype('category')\nmemory_usage2 = df['Type'].memory_usage()\nprint('Memory usage after changing to categorical type: ',memory_usage2)\nprint('Changing to categorical type reduced the used memory by:' ,(1- memory_usage2/memory_usage1)*100,'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Initial Type values: ',df.Type.unique())\ndf.Type.replace({'h':'house','u':'unit','t':'town_house'}, inplace = True)\nprint('The more representative values: ',df.Type.unique())\nprint(' ')\ndf['Type'].value_counts(normalize = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data type conversions** _ to categorical","metadata":{}},{"cell_type":"code","source":"#Categorical Data\ndf['Suburb'] = df['Suburb'].astype('category')\ndf['Postcode'] = df['Postcode'].astype('category')\ndf['Regionname'] = df['Regionname'].astype('category')\ndf['Real_Estate_Agent'] = df['Real_Estate_Agent'].astype('category')\ndf['Type'] = df['Type'].astype('category')\ndf['Method'] = df['Method'].astype('category')","metadata":{"_uuid":"10c47812-3ffa-4ba4-b51b-c0948e13dd28","_cell_guid":"e3be1863-e20c-44ac-945b-6e3630807d1e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling missing values","metadata":{}},{"cell_type":"code","source":"# finding the columns with missing data\npd.isnull(df).any(axis = 0) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns = ['YearBuilt', 'BuildingArea', 'CouncilArea'], inplace = True) #Dropped this column since this data point was poorly sourced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df = df.fillna(df.mean())  # fill with the mean of the column\n# df = df.fillna(df.max())  # fill with the max of the column\ndf['Car'] = df['Car'].fillna(df['Car'].mean())    # setting missing values to zero\npd.isnull(df).any(axis = 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data type conversions** _ to integer","metadata":{}},{"cell_type":"code","source":"#Integer Data\ndf['Car'] = df['Car'].astype('int64')\ndf['Rooms'] = df['Rooms'].astype('int64')\ndf['Bedroom2'] = df['Bedroom2'].astype('int64')\ndf['Bathroom'] = df['Bathroom'].astype('int64')\ndf['Price'] = df['Price'].astype('float64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data type conversions** _ to date","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.Date.dtypes)  # Columns with mixed types are stored with theÂ object dtype.\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['Date'].dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting month\ndf['Month'] = df['Date'].dt.month\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sorting records based on a column values","metadata":{}},{"cell_type":"code","source":"# After sorting, we have to reset the index:\ndf = df.sort_values('Price',ascending = False).reset_index() # Default is ascending\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The split function, as the name suggests, splits a string at the specified character \ndf['road_type'] = df['Address'].str.split(' ').str[-1]\ndf.road_type.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardizing the text formats. \ndf['Address'].str.upper()\ndf['Type'] = df['Type'].str.capitalize()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### iloc vs. loc","metadata":{}},{"cell_type":"code","source":"print(\"\\n -- loc -- \\n\")\nprint(df.loc[df['Price'] < 150000, ['Type']])\n \nprint(\"\\n -- iloc -- \\n\")\nprint(df.iloc[(df['Price'] < 150000).values, [4]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[[1]].to_dict('records')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df['Type'] == 'House',['Type','Price','Distance','Regionname']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_filtered = df.loc[(df['Type'] == 'House') & (df['Distance'] <= 0.5 * np.median(df['Distance'])) & (df['Rooms'] <= 2),['Type','Price','Distance','Regionname','Rooms']]\ndf_filtered","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The mean Price of a property meeting our criteria is: ',\"${:,.2f}\".format(np.mean(df_filtered['Price'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis & Visualization\n\n## **Groupby**\n#### Groupby is a versatile and extremely useful function for exploratory data analysis","metadata":{}},{"cell_type":"code","source":"# distribution of the available data over collected dates  \ndf['Date_only']=df['Date'].dt.date\nax = df.groupby(['Date_only'])['Price'].count().plot(kind = 'bar', figsize = (30,10))\nax.set_ylabel(\"Number of records\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can see the irregularity in the number of data points for the recorded dates. ","metadata":{}},{"cell_type":"code","source":"# Mean price on each of the collected dates \nax = df.groupby(['Date_only'])['Price'].mean().plot(kind = 'bar', figsize = (30,10))\nax.set_ylabel(\"Price\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization\nplt.figure(figsize=(10, 8), dpi=80)\nbox_plot = sns.boxplot(x = 'Type',y = 'Price',data = df.sort_values('Type'))\nplt.ylabel('Price')\nplt.xlabel('Property Type')\n\nax = box_plot.axes\nlines = ax.get_lines()\ncategories = ax.get_xticks()\n\nfor cat in categories:\n    # every 4th line at the interval of 6 is median line\n    # 0 -> p25 1 -> p75 2 -> lower whisker 3 -> upper whisker 4 -> p50 5 -> upper extreme value\n    y = round(lines[cat*6+2].get_ydata()[0],1) \n    y2 = round(lines[cat*6+4].get_ydata()[0],1) \n\n    ax.text(\n        cat, \n        y, \n        f'{y}', \n        ha='center', \n        va='center', \n        fontweight='bold', \n        size=10,\n        color='white',\n        bbox=dict(facecolor='#445A64'))\n    ax.text(\n        cat, \n        y2, \n        f'{y2}', \n        ha='center', \n        va='center', \n        fontweight='bold', \n        size=10,\n        color='white',\n        bbox=dict(facecolor='#445A64'))\n\nbox_plot.figure.tight_layout()\n\nfig = box_plot.get_figure()\n\n# fig.savefig(\"age.png\",dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are a few outliers after the max value and the minium price of all is \\\\$85,000. \n#### \\\\$85,000 for a property is very low for Melbourne. Let's find this cheapest property: ","metadata":{}},{"cell_type":"code","source":"max_price = np.max(df['Price'])\nmin_price = np.min(df['Price'])\nmid_price = np.median(df['Price'])\n\ndf[df['Price'].isin([min_price,mid_price,max_price])].sort_values(by = ['Price'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_Lattitude = df[df['Price'] == min_price]['Lattitude'].values[0]\nmin_Longtitude = df[df['Price'] == min_price]['Longtitude'].values[0]\n\nfig = px.density_mapbox(df[df['Price'] == min_price], lat='Lattitude', lon='Longtitude', z='Price', radius=15,\n                        center=dict(lat=min_Lattitude, lon=min_Longtitude), zoom=14,\n                        mapbox_style=\"stamen-terrain\", opacity = 1, title = 'Cheapest Property Neighborhood')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 8), dpi=80)\nsns_plot = sns.violinplot(x = 'Type',y = 'Rooms',data = df.sort_values('Type'), split = False)\nplt.ylabel('Number of Rooms')\nplt.xlabel('Type')\nplt.title('A kernel density estimation of Number of Rooms for each Property Type')\nfig = sns_plot.get_figure()\n# fig.savefig(\"mas.png\",dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can use pivot table and then plot it to compare the price of \n# properties in different regions grouped by their type\n\ndf.pivot_table(index='Type', values='Price', aggfunc='mean',columns='Regionname')\\\n.plot(kind=\"bar\",figsize=(10, 8))\nplt.ylabel('Mean Price')\nplt.title('Southern Metropolitan is constistanly the most expensive region')\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# another approach is using groupby:\ndf[['Price','Type','Regionname']]\\\n.groupby(['Type','Regionname']) .agg(['mean']).sort_values(by=(\"Price\", \"mean\"))\\\n.dropna().unstack().plot(kind='bar',figsize=(10, 8))\nplt.ylabel('Mean Price')\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bedroom2 (Scraped # of Bedrooms (from different source)) is not consistent with the other source:\n","metadata":{}},{"cell_type":"code","source":"df[['Type','Rooms','Bedroom2']].groupby('Type') .agg(['max','min','mean']).round(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can use **px.density_mapbox**, and  **Lattitude** and **Longtitude** columns in the data, to overlay the data points on map.\n\n#### Each row of the DataFrame is represented as a point smoothed with a given radius of influence.","metadata":{}},{"cell_type":"code","source":"fig = px.density_mapbox(df, lat='Lattitude', lon='Longtitude', z='Price', radius=10,\n                        center=dict(lat=-37.8, lon=145), zoom=10,\n                        mapbox_style=\"stamen-terrain\", opacity = 0.5, title = 'Melbourne Price Heatmap')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.density_mapbox(df, lat='Lattitude', lon='Longtitude', z='Landsize', radius=10,\n                        center=dict(lat=-37.8, lon=145), zoom=10,\n                        mapbox_style=\"stamen-terrain\", opacity = 0.5, title = 'Melbourne Landsize Heatmap',range_color=(0,3000))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monthDict = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \n            7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\ndf.pivot_table(index='Type',columns='Month', values=['Price', 'Propertycount'], aggfunc={'Price':'count'}).rename(columns=monthDict, level=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import calendar\ndf['Month2'] = df['Month'].apply(lambda x: calendar.month_abbr[x])\n\n\ndf.pivot_table(index='Type',columns='Month', values=['Price', 'Propertycount'], aggfunc={'Price':'count'})\\\n.rename(columns=monthDict, level=1).plot(kind=\"bar\",figsize=(10, 8))\nplt.ylabel('Count')\nplt.title('Distributions are normal like for all the types, peaking in the middle of the year')\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n\n\ndf.pivot_table(index='Type',columns='Month', values=['Price', 'Propertycount'], aggfunc={'Price':'mean'})\\\n.rename(columns=monthDict, level=1).plot(kind=\"bar\",figsize=(10, 8))\nplt.ylabel('Mean Price')\nplt.title('The Supply and demand is reflected in that the price drops in the middle of the year')\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation of Price with other features\n\n#### Correlation matrix can only be used for numberical variables. \n\n#### Here are some common sense assumptions:\n1. **Landsize and Price are probably highly correlated.** I believe that in Melbourne as land size increases the house prices will increase linearly to that. \n2. **Rooms, Bathroom and Carpark should be highly correlated.** Same logic as point 1, the bigger the house the higher the price.\n3. **In Australia the CBD(Central Business District) tends to be prime property.** The reason for that is every aminety is readily avialable and being close to work is a huge advantage consdering all work offices tend to be within the CBD.\n4. Certain Real Estate agents will be \"expert sellers\" in certain locations within Melbourne. The rationale behind this one is simple, a real estate agent might pick niche which makes them the specialist in selling houses in a given area. \n","metadata":{}},{"cell_type":"code","source":"#Numerical Dataset\ndf_numerical = pd.concat([df['Price'], df['Distance'], df['Rooms'], df['Bathroom'], df['Car'], df['Landsize']], axis = 1)\ndf_numerical = df[['Price','Distance','Rooms','Bathroom','Car','Landsize']]\n#df_numerical = df.select_dtypes(include='number')\ndf_numerical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_numerical.corr(), annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df_numerical)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Orighty, this pairplot has lot going on so lets take it step-by-step. Firstly, Landsize data has an outlier sticking out. We can get rid of the outlier which will give us some more meaningful insights (will do this in a bit).\n\nNow lets look at Distance. The Distance variable is exhibiting a sort of positively skewed bell curve characteristics when plotted against Price. It seems that as distance reduces prices increase not strictly linearly, this maybe why the correlation matrix was showing strange values. But from the pairplot we can observe the 4th assumption in full effect which is awesome! There are obvious relationships with distance such as distance increases (moving out of CBD) Rooms, Bathrooms and Car space will increase. I do not want to spend too much time on this at the moment.\n\nFinally, looking at Rooms, Bathrooms and Car we can observe a loosely positive increase in price as there is a positive 1-unit change in the three variables. Once again this does not indicate that there is a strict linear relationship, we have to always take this kind of analysis with a grain of salt.\n","metadata":{}},{"cell_type":"code","source":"#Removing the outlier from Landsize var, I am going to remove the row exhibiting the Landsize outlier completely\ndf_numerical_2 = df_numerical.drop(df_numerical['Landsize'].idxmax())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numerical_2 = df_numerical.drop(df_numerical.index[df_numerical['Landsize'] > 10000])\n#df.loc[df['B'] == 19]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" sns.boxplot(y = df_numerical_2.Landsize, data = df_numerical_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df_numerical)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/91/db/a8/91dba80a5419f1bf4700ec99ab6081bb.jpg)","metadata":{}}]}